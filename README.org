Introduction to R programming for criminology

DOWNLOAD LINK: https://github.com/tdhock/intro-R-criminology/archive/master.zip

** Overview of topics to discuss

- [[#what-is-r][What is R]]? 20 minutes. Brief history. Why use R? Obtaining
  R. Interfaces to R.
- [[#r-basics][R basics]]. 60 minutes. Getting interactive help. Vectors, types,
  calling functions, names, subsetting.
- [[#what-are-r-packages][What are R packages]]? 60 minutes. Installing packages from CRAN and
  GitHub. Attaching packages. How to find packages?
- [[#datatable-an-efficient-package-for-data-manipulation][data.table]], an efficient package for data manipulation.
- [[#criminology-data-visualization-with-ggplot2][ggplot2]], a package for data visualization based on the grammar of
  graphics.
- [[#extra-topics][Extra topics]]: regular expressions, reading/writing STATA/SPSS/SAS
  files in R, for/while/if.

** What is R? 
   
*** Brief history

R is a free/open-source programming language and environment for data
analysis and visualization. It is a free/open-source implementation of
the S language, which was originally created by John Chambers at Bell
Labs in the 1970s. S was sold as commercial software starting in the
1980s (like SPSS 1968, SAS 1976, STATA 1985). Then in 1993 Ross Ihaka
and Robert Gentlement decided to write R, a new free/open-source
implementation of S. Now there are over a dozen [[https://www.r-project.org/contributors.html][R Core team members]]
(mostly statistics researchers and professors), who are responsible
for the development of the base R system.

*** Why use R? 

*R is free, unlike most other statistical software.* If you know how
to use other statistical software (SPSS, SAS, STATA), and you want to
learn R, try reading [[http://www.burns-stat.com/documents/tutorials/r-relative-to-statistical-packages/][R Relative to Statistical Packages]] and the links
therein. The final quote by Jonathan Baron is

#+BEGIN_SRC text
Another point, which I repeatedly make to students, is that R is free
and will continue to exist. Nothing can make it go away. Once you
learn it, you are no longer subject to price increases (e.g., from
zero, when, as a grad student, you use your advisor’s copy of SAS, to
several hundred dollars or more after you leave). You can take it with
you wherever you go. The investment in learning thus has a long-term
payoff.
#+END_SRC

Note that R is free software both in the sense of "free beer" (no
cost), and "free speech" (you can do whatever you want with it -- this
includes viewing, copying, and modifying the source code).

*R is a programming language*, which means you can use it to do any
computations you want (see [[http://www.burns-stat.com/documents/tutorials/impatient-r/more-r-blank-screen-syndrome/][More R Blank Screen Syndrome]], part of
Impatient R by Pat Burns).

*R is likely the first place that new, state-of-the-art data analysis
software will appear.* This is mainly because there are so many other
people using it -- since R is free, anyone can contribute to improving
it. Pieces of software that extend R are called "packages" which are
useful for all sorts of things, for example

- There are many packages for machine learning in R ([[https://cran.r-project.org/web/packages/mlr/vignettes/mlr.html][mlr]], [[https://topepo.github.io/caret/][caret]]).
- My research project involves developing new machine learning models
  for genomic data, including my recent work on the first log-linear
  time algorithm for constrained optimal segmentation ([[https://github.com/tdhock/coseg][coseg]]).
- In this tutorial we will discuss [[http://ggplot2.org/][ggplot2]], an implementation of
  Wilkinson's Grammar of Graphics. It is a great package for static
  data visualization (making figures for your papers).
- Since 2013 my Google Summer of Code students have been helping me to
  develop [[https://github.com/tdhock/animint][animint, a package for animated interactive data
  visualization]]. It can be used to create interactive web graphics for
  all kinds of data ([[http://members.cbio.mines-paristech.fr/~thocking/WorldBank-facets/][World Bank life expectancy and fertility rate]],
  [[http://members.cbio.mines-paristech.fr/~thocking/figure-timeseries/][temperature in my bioinformatics office]]).

*** Obtaining R

CRAN is the Comprehensive R Archive Network, a set of identical web
sites from which R and its packages can be downloaded. All the web
sites are copied from http://cran.r-project.org, but for speed you
should use the mirror which is closest to you (in Montreal the closest
is currently in [[http://cran.utstat.utoronto.ca/][Toronto]]).

*** Command line versus graphical user interface

R has a command line interface. So you can either (1) type R code
interactively at the R command line, or (2) type R code into a plain
text file (an R script) and then execute that file in R.

RStudio is a graphical user interface for R (developed by the
RStudio company, not by the R Core Team). It simplifies writing and
executing R code. It is recommended to use RStudio for this tutorial.

*** Summary

- The base R system is free/open-source software developed since 1993
  by R-core, a team of statisticians and programmers.
- There are many reasons to use R (free, popular, state-of-the-art).
- R and its source code can be obtained free of charge from CRAN, the
  Comprehensive R Archive Network.
- R is inherently a command line program, but there are several
  graphical user interfaces, including RStudio.

** R basics

*** Getting interactive help

To see an example of how to use an R function =FUN=, use
=example(FUN)=. *Exercise:* open an R session on the command line or
in RStudio. Execute the following line of code to see an example of
how to compute the sample mean using the =mean= function.

#+BEGIN_SRC R
  example(mean)
#+END_SRC

Note: we say that we are calling the function =example= with the
argument =mean=.

*** R is a vectorized language

We say that R is a vectorized language because most data in R is a
*vector* (with N > 1 elements), as opposed to a *scalar* (with 1
element). For example the variable =x <- c(0:10, 50)= is a numeric
vector of length 12. The =mean= function takes a vector argument like
=x= and returns its mean as a scalar.

#+BEGIN_SRC R
  x <- c(0:10, 50)
  x
  str(x)
  xm <- mean(x)
  str(xm)
#+END_SRC

Note that 
- =:= is the colon operator, for constructing a sequence (in this case
  the integers from 0 to 10).
- =c= is a function that *c*oncatenates its arguments (separated by
  commas) into a vector. =0:10= is the first argument and =50= is the
  second argument.
- =<-= is the assignment operator that takes the value on the right
  and assigns it to the variable name on the left. When I read it, I
  think "gets" or "is assigned the value of" (like an arrow pointing
  left, not less than minus).
- =str= is a function that prints the *str*ucture of any R object.

*Exercise:* open a new R script called =exercises.R= where you write
and execute the following R code. Create a vector of integers from 50
to 65, then store it in the variable =positive.vec=. Create another
vector of integers from -10 to -5, then store it in the variable
=negative.vec=. Concatenate these two vectors and store the result in
a new variable called =positive.and.negative.vec=. Use =str= on the
new variables that you have created. What differences are there with
the output of =str(x)=?

*** Types in R

Note: you can get help about any function in R using =help("name of
the function")=, for example =help("<-")= or =help(":")=.

*Exercise:* read =help(":")=. The Value section describes the return
value of the function. What is the type?

There are three basic types of *atomic vectors* you will most often
use in R: double, integer, and character. These types are reported by
=str= (along with others we will discuss later). Atomic means that
each element of the vector has the same type.

| C type | str() | R as.*       | R is.*       | literals             |
|--------+-------+--------------+--------------+----------------------|
| double | num   | as.double    | is.double    | 0, 1e-5, Inf, 2e-308 |
| int    | int   | as.integer   | is.integer   | 0L, 50L, -6L         |
| char*  | chr   | as.character | is.character | "0" or '0' or "zero" |

- Literals are what you write in R code to express a certain
  value. The e is short for exponent (times 10^), Inf is short for
  infinity, and L is short for long integer.
- Note that =num= is short for "numeric" and =double= is short for
  "double precision floating point" (real number possibly with
  decimal).

*Exercise:* Use =str= to find out the types of the following R
 expressions. What can you conclude about the rules that =c= uses to
 concatenate values of different types?

#+BEGIN_SRC R
  0:10
  50
  "15"
  c(0:10, 50, "15")
#+END_SRC

*Exercise:* use the as.* functions to convert between types. Can you
predict the output?

#+BEGIN_SRC R
  ## what happens when you convert double to int or character?
  x <- c(0:10, 50)
  as.integer(x)
  as.character(x)
  ## what happens when you convert character to int or double?
  chr.vec <- c("0", "-5.5", "2", "Inf", "Male", "Female")
  as.integer(chr.vec)
  as.double(chr.vec)
#+END_SRC

*** Calling functions with positional versus named arguments

There are two ways to specify arguments to functions in R. So far we
have mostly seen *positional arguments*, fun(value1, value2). In the
code below, we say that =0:10= is the first argument of =c= and =50=
is the second argument (separated by commas).

#+BEGIN_SRC R
  num.vec <- c(0:10, 50)
  mean(num.vec)
#+END_SRC

But we can also use *named arguments*, fun(name1=value1,
name2=value2), which are also separated by commas. Note that
- named arguments can appear in any order (not necessarily the same
  order as on the help page).
- if you don't specify an argument at all (for example na.rm on the
  first line below), then it takes its default value (as specified on
  the function's help page).

#+BEGIN_SRC R
  mean(x=num.vec)
  mean(x=num.vec, na.rm=TRUE)
  mean(na.rm=TRUE, x=num.vec) 
#+END_SRC

You can also mix positional with named arguments. 

#+BEGIN_SRC R
  na.vec <- c(NA, num.vec)
  mean(na.vec)
  mean(na.vec, na.rm=TRUE)
#+END_SRC

By the way, =NA= is short for "none associated" -- a missing
value. And "rm" is short for "remove" so =na.rm= is short for "remove
missing" values.

*Exercise:* type =NA= and then TAB at the R command line -- you should
see a list of R objects that begin with NA. Use =str= to find out the
types of each (yes, there are different types of missing
values). Usually you can just use =NA= (without any suffix) in your R
code to indicate a missing value, but sometimes it will be necessary
to specify the type (using one of the suffixes).

*Exercise:* what happens when you use =c= with named arguments?

*** Names and subsetting

Most R objects can have names. For example consider the following
vector which stores the birth years of several of my family members.

#+BEGIN_SRC R
  birth.year.vec <- c(
    Toby=1984,
    Maude=1983,
    Morgan=1985)
  birth.year.vec
  str(birth.year.vec)
#+END_SRC

You can use subset operations to look up the birth year of a person by
name or number. The double-square-bracket operator is used to select
exactly one element:

#+BEGIN_SRC R
  birth.year.vec[["Toby"]]
  birth.year.vec[[1]]
#+END_SRC

Note that the help page is =help("[[")=.

*Exercise:* select one of the other elements of =birth.year.vec=,
using a name or a number.

*Exercise:* what are some names and numbers that you think should not
work? Why? Try them.

The single-square-bracket operator is used to select any number of
elements:

#+BEGIN_SRC R
  birth.year.vec[c("Maude", "Toby")]
  birth.year.vec[c(1, 3)]
  birth.year.vec[-1]
  birth.year.vec[0]
#+END_SRC

*Exercise:* select another subset (say Toby and Morgan) using a
variable. Hint: use the =<-= assignment operator to assign a name or
number to a new variable name.

*Exercise:* what happens when you use missing values, large numbers,
or unknown names?

*** Summary
- R has an interactive help system, =help(fun)= and =example(fun)=.
- Most data in R are vectors which are usually one of three basic
  types: double, integer, character.
- Functions can be called using either positional or named arguments.
- Most R objects can have names, which are useful in subset
  operations.

** What are R packages? 

R packages contain R code and data sets which extend the functionality
of R. There are thousands of R packages, each with different
functions, developed by different people. For example in this tutorial
we will discuss the [[https://CRAN.R-project.org/package=data.table][data.table]] package.

*Exercise:* to check if the data.table package is installed, type the
following on the command line:

#+BEGIN_SRC R
  library(data.table)
#+END_SRC

If the package is not present, there will be an error message

#+BEGIN_SRC R
Error in library(data.table) : there is no package called ‘data.table’
#+END_SRC

Whenever you get an error message, you can usually get more
information about what that error means by looking up the help page of
the function that you were using. *Exercise:* use the help system to
figure out where the =library= function looks for packages. Hint:
check the =lib.loc= argument.

*** install.packages from CRAN to your computer

=install.packages("data.table")= means "download the most recent
version of the data.table package from CRAN, and install it for use on
my local computer." *Exercise:* install the data.table package.

More precisely, =install.packages= looks for the package in the web
sites listed in

#+BEGIN_SRC R
  getOption("repos")
#+END_SRC

and installs the first package it finds to the first item of
=.libPaths()=. Note that the =repos= option in RStudio defaults to
"https://cran.rstudio.com" and can be changed in Tools -> Global
Options -> Packages -> CRAN mirror. If you don't use RStudio, you can
use the R code

#+BEGIN_SRC R
options(repos=c(
          "http://www.bioconductor.org/packages/release/bioc",
          "http://r-forge.r-project.org",
          "http://probability.ca/cran",
          "http://cran.r-project.org"))
#+END_SRC

Note: if you put the above code in your =~/.Rprofile= file, it will be
executed every time R is started. The =~= means "home directory" and
it can be found on your computer via the R command

#+BEGIN_SRC R
normalizePath("~")
#+END_SRC

*** install_github packages to your computer

Some new versions of CRAN packages can be downloaded from GitHub, a
web site that provides free code hosting for free/open-source
projects. For example a newer version of data.table is available from
https://github.com/Rdatatable/data.table and installable via the R
commands

#+BEGIN_SRC R
remotes::install_github("Rdatatable/data.table")
devtools::install_github("Rdatatable/data.table")
#+END_SRC

The double colon syntax means =package::object= -- in this case it
means that both the =remotes= and the =devtools= packages contain a
function called =install_github=. Both should work for installing
packages from GitHub.

*Exercise:* install the =namedCapture= package for named capture
regular expressions from one of my github repositories,
https://github.com/tdhock/namedCapture. Hint: you will first need to
use =install.packages= to get a copy of either =remotes= or
=devtools=.

Caveat: some R packages contain compiled code. Packages with compiled
code are compiled to binary form for you on CRAN, but not on
GitHub. So if you want to install one of these packages from GitHub,
your computer will need a compiler.
- Windows Rtools http://cran.r-project.org/bin/windows/Rtools/
- Mac Xcode https://developer.apple.com/downloads
- Linux usually has compilation tools by default, but you may need to
  run a command like =sudo aptitude install r-base-dev=.

*** Attaching packages

There are two ways of accessing functions and data in a package. For
example consider the =install_github= function in the =remotes=
package. You can either use that function via

#+BEGIN_SRC R
remotes::install_github("Rdatatable/data.table")
#+END_SRC

which does NOT attach the package. Otherwise you can attach the
package with =library=, which gives you access to all its exported
functions without having to use the =remotes::= prefix.

#+BEGIN_SRC R
library(remotes)
install_github("Rdatatable/data.table")
#+END_SRC

There are advantages and disadvantages to both approaches:
- *Attach using library for convenient interactive use* when a package
  is attached, its contents are available for TAB-completion.
- *Use double-colon syntax to clarify where each function comes from.*
  If you see an R script with only =install_github= (no pkg::) you may
  wonder, in which package is that defined?
Note that both approaches will *load* the package into memory.

To see a list of currently attached packages, check the search list.

#+BEGIN_SRC R
  search()
#+END_SRC

Note: there is also the triple-colon syntax =pkg:::object= which can
be used to access non-exported objects in a package that are supposed
to be hidden from the user. However, since R is free/open-source
software, the source code for everything is available (even
non-exported objects). This is sometimes useful when you really want
to see how someone else's code works, for example =cghseg:::segmeanCO=
is an R interface to C code that solves an optimal change-point
detection problem.

*** Getting package help

First of all, packages contain help pages in the same format as the
base R system. So after you have loaded a package, you can use
=help(fun)= and =example(fun)= to get help.

*Exercise:* open the help page for the =install_github= function. Now
close your R session with =q()= or by using the Rstudio
interface. Open a new R session and read the help page for
=install_github=. 

*Vignettes* are not required elements of a package. When they are
present, they are usually very useful, and probably the first place
you should look. A vignette is a short textual description of how to
do something in R, along with code and output. For a list of all the
vignettes in the data.table package, do

#+BEGIN_SRC R
vignette(package="data.table")
#+END_SRC

To read one of the vignettes we will discuss later in this class, do

#+BEGIN_SRC R
  vignette("datatable-reshape", package="data.table")
#+END_SRC

Vignettes are also listed on the package's CRAN page
http://cran.utstat.utoronto.ca/web/packages/data.table/index.html

To list *all* vignettes available in your copy of R, do

#+BEGIN_SRC R
  vignette()
#+END_SRC

*** How to find packages?

- [[https://cran.r-project.org/web/views/][Task views]] are topic-based lists of packages.
- There are various local ([[http://www.meetup.com/Montreal-R-User-Group/][Montreal R User Group]], [[http://raquebec.ulaval.ca/2017/][R à QC]]) and
  international meetings ([[https://user2017.brussels/][useR2017 in Brussels]]).
- Community news sites: [[https://www.r-bloggers.com/][R-Bloggers]], [[https://rweekly.org/][RWeekly]].

*Exercise:* it seems to me like network analysis and visualization is
an important topic in criminology. go to the Task Views web page, and
try to find an R package for network visualization. Hint: in
statistics we refer to data visualization as statistical graphics.

*Get involved with the R community.* There is not yet an R task view
for criminology. R is an open project, so you could be the first to
create one! All you need is some time to review the existing packages,
and to write some brief summary of how the relevant ones are useful
for criminology. (you can also ask for contributions from others who
use R in your field)

*** Section summary

- An R package contains code and data for a specific field of data
  analysis.
- =install.packages= downloads the most recent version of a package
  from CRAN, and installs it on your computer.
- =install_github= downloads a package from GitHub, and installs in on
  your computer.
- Packages can be used either via double-colon syntax or via
  =library=.
- There are a variety of resources online and in real life to help you
  find packages for particular problems.

** End of first half-day class

   Thanks for participating in this first introduction to R programming
   class. Please fill out a short survey and read the following before
   the next class.

*** Survey

    https://docs.google.com/forms/d/e/1FAIpQLSfTYlOBCPs7eYLRmgs_L5nCOvPEJcooSRlNy8DWScWwvAnEyA/viewform?usp=sf_link

*** Homework / further reading

    Patrick Burns' [[http://www.burns-stat.com/documents/tutorials/impatient-r/][Impatient R]].

    #+BEGIN_SRC R
  vignette("datatable-intro", package="data.table")
  vignette("datatable-reshape", package="data.table")
    #+END_SRC

** data.table, an efficient package for data manipulation

*** Introduction to data.frame

A =data.frame= is the object which represents a two dimensional data
table (a CSV file). Like CSV files, a data.frame can have columns of
different types. For example, let's read a small data set using the
base R function =read.csv=. Begin by downloading [[https://raw.githubusercontent.com/tdhock/intro-R-criminology/master/melt_default.csv][melt_default.csv]] to
your computer, and take note where you save it -- you will need to
tell R where to look for it. Use =getwd()= to get the "working
directory" and use =setwd("/path/to/a/directory")= to set it. R
functions that operate on files are always relative to the working
directory.

Example 1 (Linux or Mac): you saved the file to
=~/Downloads/melt_default.csv= (tilde =~= means your home
directory). Then you could read it via either

#+BEGIN_SRC R
  setwd("~/Downloads")
  families.df <- read.csv("melt_default.csv")
#+END_SRC

or

#+BEGIN_SRC R
  families.df <- read.csv("~/Downloads/melt_default.csv")
#+END_SRC

Example 2 (Windows): for each data analysis project, I save all data
files and R scripts in the same directory. If you save the CSV file to
=C:\projects\intro-R-criminology= then you could do

#+BEGIN_SRC R
  setwd("C:\projects\intro-R-criminology")
  read.csv("melt_default.csv")
#+END_SRC

Once you have read the CSV file, you can display it in R via

#+BEGIN_SRC R
  families.df
  str(families.df)
#+END_SRC

Note that the date columns are each read as a *factor*, which is an
integer vector with associated character *levels*. This is a type that
R uses to represent categorical data. For more info read
=help(factor)= and =help(levels)=.

You can think of a data.frame as a list of columns, each is a vector
of the same size, but of different type. Say we want to perform some
computation on all families with a mother younger than 30. First we
need to select the =age_mother= column, which we can do using the
double-square-bracket operator, or the dollar-sign operator (which is
just an abbreviation for the case of selecting a column with a literal
name).

#+BEGIN_SRC R
  families.df[["age_mother"]]
  families.df$age_mother
  families.df$age_mother < 30
#+END_SRC

Note that the less-than operator =<= is used to create a logical
vector that we can use to determine if each row meets our selection
criteria: TRUE for age less than 30, FALSE otherwise. Read =help("<")=
for more info about this and other binary operators.

*Exercise:* how could you select only the families with 3 children?
Hint: try looking at the help pages of =is.na=, and =!=.

The single-square-bracket operator works differently for data.frames
-- it takes two arguments:
- the first argument is used to select a subset of rows,
- the second argument is used to select a subset of columns.

Thus to select all families with a mother younger than 30, we can write

#+BEGIN_SRC R
  families.df[families.df$age_mother < 30, ]
#+END_SRC

*Exercise:* how would you select all families with three children, and
a mother who is less than 30? Hint: read =help("&")=.

Already for this very simple operation we have to repeat ourselves in
the code (we mention the =families.df= data.frame twice in the code
above).

*** Advantages of data.table

=data.table= is a package that provides an efficient alternative to R's
native =data.frame=. How is it more efficient?
- Faster to code. Less repetition.
- Faster computation. Less copying objects in memory.

Let's perform the same operations as the previous section using the
=data.table= package, which contains the =fread= function for reading
CSV files.

#+BEGIN_SRC R
  library(data.table)
  families.dt <- fread("melt_default.csv")
  families.dt
  str(families.dt)
#+END_SRC

Note how the data.table displays almost the same as the data.frame in
the output. *Exercise:* talk with your neighbor, what are the
differences?

To select the subset of families with a mother younger than 30, we can
use variable names directly in the first argument (without a second
reference to =families.dt=).

#+BEGIN_SRC R
  families.dt[age_mother < 30, ]
#+END_SRC

*Exercise:* how would you select all families with three children, and
a mother who is less than 30?

For more information about selecting subsets, read
=help("[.data.table")= (especially the examples section).

*Exercise:* try timing =read.csv= versus =fread= using the base
=system.time= function, or the =microbenchmark= package. On this small
data set, there should not be a huge difference. But on larger data
sets (over 10MB, [[http://cbio.ensmp.fr/~thocking/data/overlap-benchmark.tgz][for example]]), there should be noticeable speed
advantage for =fread=.

#+BEGIN_SRC R
  system.time(big.df <- read.table("overlap-benchmark/chip-seq.bedGraph"))
  system.time(big.dt <- fread("overlap-benchmark/chip-seq.bedGraph"))
#+END_SRC

Caveat: fread is newer than read.table/read.csv, so may not work for
some very strange (badly formatted) CSV files. In that case, try
=read.table= or =read.csv=.

*** Converting between long and wide data (melt and dcast)

Work examples from [[https://cran.r-project.org/web/packages/data.table/vignettes/datatable-reshape.html][data.table reshape vignette]] on the R command line.

- Tall data is a synonym for long data in English (mais le mot
  «grande» en français est ambigu : les grandes données peuvent être
  soit larges, soit longues).
- =melt= converts from wide to long (fondre en français). The "melt"
  comes from metallurgy, to create a long "molten" =data.frame= which
  can then be cast into other formats.
- =dcast= converts from long to wide. The word "cast" is used in the
  sense of metallurgy (casting is a process in which a liquid molten
  metal is left to solidify and take the shape of a mold). The "d"
  prefix is for =data.frame= output, to contrast other types of output
  like arrays (=reshape2::acast=). En français on dit «coulage» pour
  la méthode de mise en forme d'un métal liquide, laissé refroidir
  dans une moule pour se solidifier. (verbe couler?)

#+BEGIN_SRC R
  children <- melt(
    families.dt,
    measure.vars=c("dob_child1", "dob_child2", "dob_child3"),
    id.vars=c("family_id", "age_mother"),
    variable.name="child",
    value.name="dob")
  dcast(children, family_id + age_mother ~ child)
#+END_SRC

*Exercise:* all of the arguments to =melt= are optional (besides the
first). What happens if you do not specify some of them?

*Exercise:* what happens if you remove the missing (NA) rows and then
do the dcast again?

*Exercise:* what happens if you remove all of the third children
(dob_child3) and then do the dcast again?

Recommended reading: Tidy data JSS paper
https://www.jstatsoft.org/article/view/v059i10

*** DT[, values] for computing on columns

If an R expression is provided as the second argument to the
data.table square-bracket operator, then it will be evaluated using
the variables in that data.table:

#+BEGIN_SRC R
  children[, age_mother]
  children[, age_mother - 20]
#+END_SRC

A new data.table will be returned if you use =list=, =.=, or =data.table=
in the second argument (they all give the same result).

#+BEGIN_SRC R
  children[, list(age_mother)]
  children[, .(age_mother)]
  only.age <- children[, data.table(age_mother)]
  family.and.age <- children[, list(
    family=family_id,
    age=age_mother)] # rename columns.
#+END_SRC

Create/update a column using the colon-equals := operator, which is
the assignment operator for columns of a data.table (like left-arrow
<- for creating R variables). Syntax is the same as left-arrow (name
<- value, name := value). There are two main differences:
- *Context:* colon-equals := can be only used in the second argument
  of a data.table, but left-arrow <- can be used anywhere outside a
  data.table.
- *Efficiency:* left-arrow <- always makes copies of memory (RAM),
  which can be problematic for large data sets. Colon-equals will
  allocate memory for a new column, but will not copy any memory when
  updating a column.
Below, we use =sub= to replace ="dob_child"= with the empty string
=""=. 
Syntax is =sub(find, replace, subject)=, for more info read =help("sub")=.

#+BEGIN_SRC R
  children[, child_order := sub("dob_child", "", child)]
  children
#+END_SRC

*Exercise:* what type is the new column =child_order=? How could you
convert it to an integer type?

*** Reading date and times into R

How could we compute the current age of each child? First we need to
convert their birthdates from character to numeric format.

=fread= converts a date/time column in a CSV file to a character
vector column of a =data.table=. The =strptime= function can be used
to convert most date/time strings to numeric format. For example let's
convert the =dob= variable from character to =POSIXct=:

#+BEGIN_SRC R
  children[, dob.POSIXct := strptime(dob, "%Y-%m-%d")]
  str(children)
#+END_SRC

Note that R has two date/time types, =POSIXct= (c is short for
"calendar time," the number of seconds since the beginning of
1970) and =POSIXlt= (l is short for "local time," a more
human-readable vector of seconds, minutes, etc). For more info read
=help("POSIXlt")=. The =strptime= function returns =POSIXlt= but
data.table converts it to the more efficient =POSIXct= type (with a
warning).

*Exercise:* Compute the age of each child.
- The =Sys.time()= function gives the current time. Use subtraction to
  compute the age of each child in days, and store that in a new
  column =age_child_days=. What is the type of that column?  (use both
  =str= and =typeof=)
- Divide by 365 to get the approximate age in years, and store that in
  a new column =age_child_years_num=. 
- Subtract from =age_mother= to get a new column =age_diff= -- what is
  the smallest value of =age_diff=? What does this tell you about
  storing ages rather than dates?

The code below displays the two new variables that we have computed,
and sorts the rows by the age of the mother.

#+BEGIN_SRC R
  children[order(age_mother), list(age_mother, age_child_years_num, age_diff)]
#+END_SRC

*Homework:* what if we wanted to compute the age in years that we say
in response to the question, "how old are you?" That is more
complicated, because the number of days per year is not constant
(usually 365 days per year, but 366 days in each leap year). Read the
rest of this section to learn how to do this computation.

We can do that by using subtraction on the years, and then comparing
the current and birth month/day. Begin by using =strftime= to compute
the current year, month, and day:

#+BEGIN_SRC R
  cur.time <- Sys.time()
  cur.year.chr <- strftime(cur.time, "%Y")
  cur.month.chr <- strftime(cur.time, "%m")
  cur.day.chr <- strftime(cur.time, "%d")
#+END_SRC

Note that strftime returns character, and can be used to format dates
and times however you like. *Exercise:* read the Details section of
=help("strftime")= and use it get the current date in "17 mars 2017"
format.

Now we compute the current year/month/day in integer format:

#+BEGIN_SRC R
  cur.year <- as.integer(cur.year.chr)
  cur.month <- as.integer(cur.month.chr)
  cur.day <- as.integer(cur.day.chr)
#+END_SRC

*Exercise:* compute the birth year, month, and day as new integer
columns (=dob.year=, =dob.month=, =dob.day=) of =children=.

The code below first computes the =had.bday= column with is =TRUE= if
the child had its birthday already this year. Note that
=ifelse(condition, value.if.true, value.if.false)= is used to
determine whether or not the child's birthday has occured this
year. Then we compute =age_child_years_int= which is the common answer
to the question "how old are you?"

#+BEGIN_SRC R
  children[, had.bday := ifelse(
    dob.month < cur.month, TRUE, ifelse(
      dob.month==cur.month, dob.day <= cur.day, FALSE))]
  children[, age_child_years_int := cur.year - dob.year - ifelse(had.bday, 0, 1)]
  children[order(age_mother), list(
    age_mother, age_child_years_num, age_child_years_int)]
#+END_SRC

Further reading about importing dates into R: one data set when
strptime did not work for me is
https://github.com/tdhock/montreal-velos/blob/master/velos.R -- I had
to use a character vector to convert non-standard month names to
numeric dates.

Packages that attempt to simplify reading of dates and times are
[[https://github.com/gaborcsardi/parsedate][parsedate]] and [[https://cran.r-project.org/web/packages/lubridate/vignettes/lubridate.html][lubridate]].

*** DT[, values, by=var] for computing values conditional on var

For every family, compute the min and max age of children.

#+BEGIN_SRC R
  age.stats <- children[!is.na(age_child_years_num), list(
    min.age=min(age_child_years_num),
    max.age=max(age_child_years_num)
    ), by=list(family_id, age_mother)]
#+END_SRC

*Exercise:* how would you compute mean and median age of children for
every family?

*** Joining data tables DT1[DT2, on=list(var1, var2)]

What if we wanted to select all children who are older than the
mean age of children in their family? We can join the =age.stats=
data.table with the =children= data.table via:

#+BEGIN_SRC R
  children.stats <- age.stats[children, on=list(family_id, age_mother)]
#+END_SRC

Note that so far in this tutorial we have only used the =DT1[var <
value, ]= syntax (logical vector for first argument of square bracket
operator). The =DT1[DT2, ]= syntax means to perform a "join" -- for
rows in the two tables which have the same values of =on=, we get a
new data.table with columns from both =age.stats= and =children=
(including =mean.age= and =age_child_years_num=).

*Exercise:* use =children.stats= to compute the subset of children
with age greater than the mean age of children in their family.

*** Data output to CSV

To save a data.table in R to disk, base R has the =write.csv=
function, and data.table has =fwrite= (faster).

#+BEGIN_SRC R
  children.not.na <- children[!is.na(dob),]
  fwrite(children.not.na, "children.csv")
#+END_SRC

*** Summary
- The data.frame object is how a CSV table is represented in base R.
- The data.table package provides a more efficient alternative (faster
  both in terms of coding and computation time).
- The =melt= and =dcast= functions can be used for converting a data set
  from long to wide format.
- =dt[, value]= returns a vector and =dt[, data.table(value1,
  value2)]= returns a =data.table=.
- dt[, colName := value] creates or updates a column.
- =strptime= converts character to numeric date/time, and =strftime=
  does the opposite.
- DT[, values, by=vars] computes values for each unique combination of
  vars.
- DT1[DT2, on=vars] joins DT1 with DT2 using the common columns vars.
- fwrite converts a data.table in R to a CSV file on disk.

** Criminology data visualization with ggplot2

*** Installing ggplot2 and reading data

The ggplot2 package implements Wilkinson's "Grammar of Graphics"
([[http://members.cbio.mines-paristech.fr/~thocking/animint-book/Ch02-ggplot2.html][brief history]]) which is extremely useful for creating a wide variety
of statistical graphics for both data exploration and publication.

*Exercise:* install the =ggplot2= package from CRAN, since we will be
using it to make the plots in this section. 

Begin by downloading [[file:specimens.csv]] which was kindly provided by
Frank.

*Exercise:* read the CSV file into R using =fread=, and assign it to
the variable =specimens=.

*** ggplots and aesthetic mappings

Start a =ggplot()=, then add a =geom_point()= to make a scatterplot.

#+BEGIN_SRC R
  ggplot()+
    geom_point(aes(x=SERVPOL, y=masse_coca), data=specimens)
#+END_SRC

The first argument to the =geom_= functions is the =aes=, short for
aesthetic mapping. The aes names correspond to visual properties in
the plot, and the values correspond to data variables. So x=SERVPOL
means that you want to plot the SERVPOL variable on the x/horizontal
axis, etc.

*Exercise:* try plotting some other variables using the x and y
aesthetics. Try aes(color=variable).

How to know what geom and aes to use? Check
http://docs.ggplot2.org/current/ for usage examples, or read
=help("geom_point")=.

*** Plotting numeric versus categorical variables

Note that the X axis is continuous since SERVPOL is numeric. To use a
categorical scale instead, create a new factor variable and plot that.

#+BEGIN_SRC R
  specimens[, SERVPOL.fac := factor(SERVPOL)]
  ggplot()+
    geom_point(aes(SERVPOL.fac, masse_coca), data=specimens)
#+END_SRC

*Exercise:* you can use =factor(values, levels)= where =levels=
specify the order of display in the categorical axis. Make a new plot
with SERVPOL.fac values which are decreasing from left to right (10
... 2 1).

*** Log axes scales

Add =scale_y_log10()= for a log scale:

#+BEGIN_SRC R
  ggplot()+
    geom_point(aes(SERVPOL.fac, masse_coca), data=specimens)+
    scale_y_log10()
#+END_SRC

*Exercise:* plot =masse_hero= versus =masse_coca=. Try a log scale for
both the x and y axes.

*** Equal horizontal and vertical coordinates

For scatterplots with the same units on both axes (in this case mass),
you can use =coord_equal()= to force a 1:1 ratio between horizontal
and vertical units, which makes it easier to compare. You can also add
an x=y line via geom_abline(slope=1, intercept=0):

#+BEGIN_SRC R
  ggplot()+
    geom_abline(slope=1,intercept=0,color="grey")+
    geom_point(aes(
      masse_specimen, masse_coca),
      data=specimens)+
    scale_y_log10()+
    scale_x_log10()+
    coord_equal()
#+END_SRC

Note that =aes= was used without specifying named arguments =x= and
=y= -- that is fine, the first argument is =x= and the second is =y=
(however all others must be named). Also note that since geom_abline
is before geom_point in the code, the abline is plotted before/under
the points.

*Exercise:* move the geom_abline after the geom_point in the code --
what happens to the plot?

Also note that since only 1 abline is plotted, you don't need to
specify the =data= argument to =geom_abline= (but you would if you
wanted to plot several ablines, one for each row in a data.table).

*** Plotting coupage counts

Frank wants to analyze the frequency of the different coupage
variables as a function of SERVPOL. 

*Exercise:* begin by melting all of the coupage columns into a
data.table called =coupage.tall= with four columns: SPECIMEN, SERVPOL,
coupage, presence. Then save all observed coupage (presence==1) in a
data.table called =coupage.present=, and compute counts by SERVPOL and
coupage:

#+BEGIN_SRC R
  coupage.present <- coupage.tall[presence==1,]
  coupage.counts <- coupage.present[, list(
    specimens=.N
  ), by=list(SERVPOL, coupage)]
#+END_SRC

Note that =.N= is a special symbol for data.tables which means "number
of rows." Now plot the counts as a heatmap using =geom_tile=:

#+BEGIN_SRC R
  ggplot()+
    geom_tile(aes(SERVPOL, coupage, fill=log10(specimens)), data=coupage.counts)
#+END_SRC

*Exercise:* the =fill= aesthetic was used to show the log10 counts of
specimens. Instead, plot the absolute integer counts (not log
scale). Which plot is more informative? Why?

The default fill colors are not too good. You can change them with
=scale_fill_= functions:

#+BEGIN_SRC R
  ggplot()+
    geom_tile(aes(SERVPOL, coupage, fill=log10(specimens)), data=coupage.counts)+
    scale_fill_gradient(low="grey95", high="red")
#+END_SRC

*Exercise:* try different colors in the fill scale. Note that all of
R's default color names can be shown via =colors()=.

Finally we use a geom_text with aes(label=specimens) to display the
count on each tile:

#+BEGIN_SRC R
  ggplot()+
    geom_tile(aes(SERVPOL, coupage, fill=log10(specimens)),
              data=coupage.counts)+
    scale_fill_gradient(low="grey95", high="red")+
    geom_text(aes(SERVPOL, coupage, label=specimens),
              data=coupage.counts)
#+END_SRC

*** Some homework

*Exercise:* right now the coupage values on the y axis are ordered
alphabetically, which does not help understand the data. Can you make
a plot with the coupage values on the y axis ordered by SERVPOL
counts? (for example vanilline was only observed in 1 SERVPOL, but
cafeine was observed in 8) First create a new =coupage.fac= variable
which is a factor with levels that are ordered according to how many
distinct SERVPOLs it was observed in (Hint: use by=coupage). Then use
aes(y=coupage.fac) in the geom_tile to make the plot. To break ties
(for example vanilline has only 1 specimen in 1 SERVPOL, but tramadol
has 4 specimens in 1 SERVPOL), try =order(servpols, specimens)=. You
should get a plot that looks like the one below.

[[file:figure-specimens-coupage-servpol.png]]

*Exercise:* install the RColorBrewer package and use
=display.brewer.all()= to see some color palettes that are very easy
to read (they are a result of years of visual perception
research). There are three groups of palettes, and the first group is
for numerical values that do not include zero. Pick one of these and
use it for the heatmap in the section above. Hint: use the
=brewer.pal= function to get a vector of hex color codes.

*Exercise:* what if we wanted to make a plot that compares the values
of all of the mass variables? Melt specimens, using the mass columns
as the =measure.vars=, then use =ggplot()+facet_grid(. ~ variable)= to
produce a multi-panel plot like the one below. Note that the red dots
show the median (compute using by=variable in the melted data.table).

[[file:figure-specimens-serv-mass.png]]

*Exercise:* use =table= to compute contingency tables (counts).

#+BEGIN_SRC R
  specimens[, table(Type)]
  specimens[, table(STUP)]
  specimens[, table(STUP, Type)]
#+END_SRC

Use =geom_bar= to plot those numbers. How could you plot
those numbers using =geom_point=?

*** Summary
- Install the =ggplot2= package to use the powerful grammar of
  graphics for data visualization.
- Start with =ggplot()= and then add geoms like =geom_point()=,
  =geom_tile()=, and =geom_text()=.
- Use =factor(values, levels)= to specify a categorical variable which
  will be ordered according to =levels=.
- Use =scale_y_log10()= for log scale axes.
- Use =coord_equal()= and =geom_abline()= when x and y axes have the
  same units.
- Use =scale_fill_gradient()= to specify a custom fill colors.
- Further reading:
http://members.cbio.mines-paristech.fr/~thocking/animint-book/Ch02-ggplot2.html

** Extra topics
*** Named capture regular expressions

These are useful when data is in some structured text format other
than CSV. For example in [[file:specimens.csv]] the SAISIE column is the
seizure ID number which looks like 

#+BEGIN_SRC R-transcript
> specimens[, list(SAISIE)]
         SAISIE
   1: 011_01.13
   2: 014_01.13
   3: 016_01.13
   4: 016_01.13
   5: 016_01.13
  ---          
2056: 475_12.13
2057: 476_12.13
2058: 476_12.13
2059: 476_12.13
2060: 477_12.13
> 
#+END_SRC

We can use the following named capture regular expression pattern to
extract the three numbers:

#+BEGIN_SRC R
  saisie.pattern <- paste0(
    "(?<id>[0-9]+)",
    "_",
    "(?<month>[0-9]+)",
    "[.]",
    "(?<year>[0-9]+)")
  match.df <- namedCapture::str_match_named(
    specimens$SAISIE, saisie.pattern, list(
      id=as.integer,
      month=as.integer,
      year=as.integer))
#+END_SRC

The =match.df= is a data.frame with columns for each capture group
(?<name>subpattern) in the regular expression pattern:

#+BEGIN_SRC R-transcript
> data.table(SAISIE=specimens$SAISIE, match.df)
         SAISIE  id month year
   1: 011_01.13  11     1   13
   2: 014_01.13  14     1   13
   3: 016_01.13  16     1   13
   4: 016_01.13  16     1   13
   5: 016_01.13  16     1   13
  ---                         
2056: 475_12.13 475    12   13
2057: 476_12.13 476    12   13
2058: 476_12.13 476    12   13
2059: 476_12.13 476    12   13
2060: 477_12.13 477    12   13
> 
#+END_SRC

For more info please read https://github.com/tdhock/regex-tutorial

*** for/while loops and if statements

A lot of R code for data analysis can be written without any for/while
loops at all. Before writing a for/while loop, it is a good idea to
ask yourself:
- Could I use by=vars in a data.table instead? If so, then it will
  probably be faster than a for/while loop.
- Can I express the computation in terms of matrix/array operations or
  vectorized functions like =cumsum=? If so, then it will probably be
  faster than a for/while loop.
You definitely should use a for loop when it should produce more than
one data.table -- in that case, use the "list of data.tables"
idiom. For example, say you have several data sets and you want to fit
a model to each, then save both the data and the model for later
analysis. The R code below is not executable, but it shows the main
idea of the idiom.

#+BEGIN_SRC R
  ## First, initialize an empty list for each data type.
  data.list <- list()
  models.list <- list()
  data.file.vec <- Sys.glob("data/*.csv")
  for(data.file in data.file.vec){
    dt <- fread(data.file)
    model.dt <- get.model.dt(dt)
    ## Save data and models using named list elements.
    data.list[[data.file]] <- dt
    models.list[[data.file]] <- model.dt
  }
  ## Combine data and model tables using rbind, which is short for row
  ## bind -- stacking rows from different data.tables on top of each
  ## other to form a big data.table.
  data.and.models <- list(
    data=do.call(rbind, data.list),
    models=do.call(rbind, models.list))
#+END_SRC

Some real examples of this idiom:
- [[http://members.cbio.mines-paristech.fr/~thocking/animint-book/Ch02-ggplot2.html][Ch2 of the Animint Designer Manual]], where a for loop is used to
  create data for two geometric plot elements (path and point).
- [[https://github.com/tdhock/change-tutorial/blob/master/Segmentor.models.R][Fitting changepoint models to the neuroblastoma data set]], where a
  for loop is used to compute data.tables which represent two
  different components of the changepoint model (loss and segments).
- [[https://github.com/tdhock/montreal-velos/blob/master/velos.R][Reading bike count data files]], [[https://github.com/tdhock/montreal-velos/blob/master/velos.dt.R][but in this example the for loop
  could be replaced with by=csv in a data.table]].

The =if= statement can be used to perform some computations only when
they are necessary (depending on the data). This is especially useful
inside of for loops, see above examples. 

More reading =help("if")=

*** Reading and writing files from other programs in R

SAS, SPSS, STATA http://haven.tidyverse.org/

Excel -- just save as CSV. Or use http://readxl.tidyverse.org/

